{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from math import log, sqrt, exp\n",
    "from scipy.stats import norm\n",
    "import sys\n",
    "sys.path.append('/Users/ansel_li/Fintech545/public/')\n",
    "from risk_mgmt import black_s, calc_return, VaR\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from scipy.stats import t, norm, spearmanr, multivariate_normal\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input parameters\n",
    "S = 151.03  # Current stock price\n",
    "K = 165  # Strike price\n",
    "t = (np.datetime64('2022-03-13') - np.datetime64('2022-03-13')).astype(int) / 365.0\n",
    "T = (np.datetime64('2022-04-15') - np.datetime64('2022-03-13')).astype(int) / 365.0\n",
    "r = 0.0425  # Risk-free interest rate\n",
    "q = 0.0053  # Continuously compounding dividend yield\n",
    "sigma = 0.20  # Implied volatility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbsm_greeks(S, K, t, T, r, q, sigma, option_type='call'):\n",
    "    tau = T - t\n",
    "    d1 = (log(S / K) + (r - q + 0.5 * sigma**2) * tau) / (sigma * sqrt(tau))\n",
    "    d2 = d1 - sigma * sqrt(tau)\n",
    "\n",
    "    N_d1 = stats.norm.cdf(d1)\n",
    "    N_d2 = stats.norm.cdf(d2)\n",
    "\n",
    "    if option_type == 'call':\n",
    "        delta = exp(-q * tau) * N_d1\n",
    "        gamma = exp(-q * tau) * N_d1 / (S * sigma * sqrt(tau))\n",
    "        vega = S * np.exp(-q * tau) * norm.pdf(d1) * np.sqrt(tau)\n",
    "        theta = -S * np.exp(q * tau) * N_d1 * sigma / (2 * np.sqrt(tau)) - r * K * np.exp(-r * tau) * -N_d2 + q * S * np.exp(-q * tau) * -N_d1\n",
    "        rho = K * tau * np.exp(-r * tau) * norm.cdf(d2)\n",
    "    elif option_type == 'put':\n",
    "        delta = -exp(-q * tau) * (1 - N_d1)\n",
    "        gamma = exp(-q * tau) * N_d1 / (S * sigma * sqrt(tau))\n",
    "        vega = S * np.exp(-q * tau) * norm.pdf(d1) * np.sqrt(tau)\n",
    "        theta = -S * np.exp(q * tau) * N_d1 * sigma / (2 * np.sqrt(tau)) + r * K * np.exp(-r * tau) * -N_d2 - q * S * np.exp(-q * tau) * -N_d1\n",
    "        rho = -K * tau * np.exp(-r * tau) * norm.cdf(-d2)\n",
    "    else:\n",
    "        raise ValueError(\"option_type must be 'call' or 'put'\")\n",
    "    return delta, gamma, vega, theta, rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call Greeks: Delta, Gamma, Vega, Theta, Rho\n",
      "(0.08297130333914773, 0.009135328237370505, 6.938710929513443, -3.7196562346632, 1.1025939156368187)\n",
      "Put Greeks: Delta, Gamma, Vega, Theta, Rho\n",
      "(-0.9165496333661425, 0.009135328237370505, 6.938710929513443, -4.623431322046896, -13.758003122735788)\n"
     ]
    }
   ],
   "source": [
    "call_greeks = gbsm_greeks(S, K, t, T, r, q, sigma, option_type='call')\n",
    "put_greeks = gbsm_greeks(S, K, t, T, r, q, sigma, option_type='put')\n",
    "\n",
    "print(\"Call Greeks: Delta, Gamma, Vega, Theta, Rho\")\n",
    "print(call_greeks)\n",
    "print(\"Put Greeks: Delta, Gamma, Vega, Theta, Rho\")\n",
    "print(put_greeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finite_difference(S, K, t, T, r, q, sigma, option_type='call', delta_shift=0.01):\n",
    "    S_up = S + S * delta_shift\n",
    "    S_down = S - S * delta_shift\n",
    "    sigma_up = sigma + delta_shift\n",
    "    sigma_down = sigma - delta_shift\n",
    "    r_up = r + delta_shift\n",
    "    r_down = r - delta_shift\n",
    "\n",
    "    def option_price(S, K, t, T, r, q, sigma, option_type):\n",
    "        tau = T - t\n",
    "        d1 = (log(S / K) + (r - q + 0.5 * sigma**2) * tau) / (sigma * sqrt(tau))\n",
    "        d2 = d1 - sigma * sqrt(tau)\n",
    "\n",
    "        if option_type == 'call':\n",
    "            return S * exp(-q * tau) * stats.norm.cdf(d1) - K * exp(-r * tau) * stats.norm.cdf(d2)\n",
    "        elif option_type == 'put':\n",
    "            return K * exp(-r * tau) * stats.norm.cdf(-d2) - S * exp(-q * tau) * stats.norm.cdf(-d1)\n",
    "\n",
    "    # Finite difference calculations\n",
    "    delta_fd = (option_price(S_up, K, t, T, r, q, sigma, option_type) - option_price(S_down, K, t, T, r, q, sigma, option_type)) / (2 * S * delta_shift)\n",
    "    gamma_fd = (option_price(S_up, K, t, T, r, q, sigma, option_type) - 2 * option_price(S, K, t, T, r, q, sigma, option_type) + option_price(S_down, K, t, T, r, q, sigma, option_type)) / (S * delta_shift)**2\n",
    "    vega_fd = (option_price(S, K, t, T, r, q, sigma_up, option_type) - option_price(S, K, t, T, r, q, sigma_down, option_type)) / (2 * 0.01)\n",
    "    theta_fd = - (option_price(S, K, t + 1/365, T, r, q, sigma, option_type) - option_price(S, K, t, T, r, q, sigma, option_type)) / (-1/365)\n",
    "    rho_fd = (option_price(S, K, t, T, r_up, q, sigma, option_type) - option_price(S, K, t, T, r_down, q, sigma, option_type)) / (2 * 0.01)\n",
    "\n",
    "    return delta_fd, gamma_fd, vega_fd, theta_fd, rho_fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call Greeks Finite Difference: Delta, Gamma, Vega, Theta, Rho\n",
      "(0.08390256513620564, 0.016848978828828364, 6.932942300084921, -8.048047189743537, 1.1026982009081365)\n",
      "Put Greeks Finite Difference: Delta, Gamma, Vega, Theta, Rho\n",
      "(-0.9156183715690898, 0.016848978828841604, 6.9329423000851875, -1.8621154051211875, -13.757900862010786)\n",
      "       Call Closed-form  Call Finite Diff.  Put Closed-form  Put Finite Diff.\n",
      "Delta          0.082971           0.083903        -0.916550         -0.915618\n",
      "Gamma          0.009135           0.016849         0.009135          0.016849\n",
      "Vega           6.938711           6.932942         6.938711          6.932942\n",
      "Theta         -3.719656          -8.048047        -4.623431         -1.862115\n",
      "Rho            1.102594           1.102698       -13.758003        -13.757901\n"
     ]
    }
   ],
   "source": [
    "call_greeks_fd = finite_difference(S, K, t, T, r, q, sigma, option_type='call')\n",
    "put_greeks_fd = finite_difference(S, K, t, T, r, q, sigma, option_type='put')\n",
    "\n",
    "print(\"Call Greeks Finite Difference: Delta, Gamma, Vega, Theta, Rho\")\n",
    "print(call_greeks_fd)\n",
    "print(\"Put Greeks Finite Difference: Delta, Gamma, Vega, Theta, Rho\")\n",
    "print(put_greeks_fd)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Combine the results in a dictionary\n",
    "greek_data = {\n",
    "    \"Call Closed-form\": call_greeks,\n",
    "    \"Call Finite Diff.\": call_greeks_fd,\n",
    "    \"Put Closed-form\": put_greeks,\n",
    "    \"Put Finite Diff.\": put_greeks_fd\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "greeks_comparison = pd.DataFrame(greek_data, index=[\"Delta\", \"Gamma\", \"Vega\", \"Theta\", \"Rho\"])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(greeks_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binomial_tree(S, K, T, r, sigma, n, option_type='call', exercise_type='american', div_date=None, div_amt=0):\n",
    "    dt = T / n\n",
    "    u = np.exp(sigma * np.sqrt(dt))\n",
    "    d = 1 / u\n",
    "    p = (np.exp((r) * dt) - d) / (u - d)\n",
    "    discount = np.exp(-r * dt)\n",
    "\n",
    "    # Create the stock price tree\n",
    "    stock = np.zeros((n + 1, n + 1))\n",
    "    stock[0, 0] = S\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        stock[i, 0] = stock[i - 1, 0] * u\n",
    "        for j in range(1, i + 1):\n",
    "            stock[i, j] = stock[i - 1, j - 1] * d\n",
    "\n",
    "    # Adjust stock prices for dividends\n",
    "    if div_date is not None and exercise_type == 'american':\n",
    "        div_steps = int((div_date - np.datetime64('2022-03-13')).astype(int) / 365.0 * n)\n",
    "        stock[div_steps:] -= div_amt\n",
    "\n",
    "    # Create the option price tree\n",
    "    option = np.zeros_like(stock)\n",
    "\n",
    "    # Calculate the option's value at maturity\n",
    "    if option_type == 'call':\n",
    "        option[:, -1] = np.maximum(stock[:, -1] - K, 0)\n",
    "    elif option_type == 'put':\n",
    "        option[:, -1] = np.maximum(K - stock[:, -1], 0)\n",
    "\n",
    "    # Step back through the tree to calculate the option's value at each node\n",
    "    for i in range(n - 1, -1, -1):\n",
    "        for j in range(i + 1):\n",
    "            option[i, j] = discount * (p * option[i + 1, j] + (1 - p) * option[i + 1, j + 1])\n",
    "\n",
    "            # Calculate the option's value if exercised early\n",
    "            if exercise_type == 'american':\n",
    "                if option_type == 'call':\n",
    "                    early_exercise = np.maximum(stock[i, j] - K, 0)\n",
    "                elif option_type == 'put':\n",
    "                    early_exercise = np.maximum(K - stock[i, j], 0)\n",
    "\n",
    "                option[i, j] = np.maximum(option[i, j], early_exercise)\n",
    "\n",
    "    return option\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def binomial_tree_greeks(S, K, T, r, sigma, n, option_type='call', exercise_type='american', div_date=None, div_amt=0, delta_shift=0.01, rate_shift=0.0001, vol_shift=0.01):\n",
    "    option_tree = binomial_tree(S, K, T, r, sigma, n, option_type, exercise_type, div_date, div_amt)\n",
    "    option_tree_S_up = binomial_tree(S * (1 + delta_shift), K, T, r, sigma, n, option_type, exercise_type, div_date, div_amt)\n",
    "    option_tree_S_down = binomial_tree(S * (1 - delta_shift), K, T, r, sigma, n, option_type, exercise_type, div_date, div_amt)\n",
    "    option_tree_vol_up = binomial_tree(S, K, T, r, sigma + vol_shift, n, option_type, exercise_type, div_date, div_amt)\n",
    "    option_tree_vol_down = binomial_tree(S, K, T, r, sigma - vol_shift, n, option_type, exercise_type, div_date, div_amt)\n",
    "    option_tree_rate_up = binomial_tree(S, K, T, r + rate_shift, sigma, n, option_type, exercise_type, div_date, div_amt)\n",
    "    option_tree_rate_down = binomial_tree(S, K, T, r - rate_shift, sigma, n, option_type, exercise_type, div_date, div_amt)\n",
    "\n",
    "    # Calculate Greeks\n",
    "    delta = (option_tree_S_up[0, 0] - option_tree_S_down[0, 0]) / (2 * S * delta_shift)\n",
    "    gamma = (option_tree_S_up[0, 0] - 2 * option_tree[0, 0] + option_tree_S_down[0, 0])/ (S * delta_shift) ** 2\n",
    "    theta = -(option_tree[0, 0] - binomial_tree(S, K, T - 1/n, r, sigma, n, option_type, exercise_type, div_date, div_amt)[0, 0]) / (1/n)\n",
    "\n",
    "    vega = (option_tree_vol_up[0, 0] - option_tree_vol_down[0, 0]) / (2 * vol_shift)\n",
    "    rho = (option_tree_rate_up[0, 0] - option_tree_rate_down[0, 0]) / (2 * rate_shift)\n",
    "\n",
    "    return delta, gamma, theta, vega, rho\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American Call Option without Dividends: 0.3317910184978169\n",
      "American Put Option without Dividends: 14.016650966102587\n",
      "American Call Option with Dividends: 0.27365120446834945\n",
      "American Put Option with Dividends: 14.86187574483816\n"
     ]
    }
   ],
   "source": [
    "n=100\n",
    "div_date = np.datetime64('2022-04-11')\n",
    "div_amt = 0.88  # Dividend amount\n",
    "\n",
    "call_without_div = binomial_tree(S, K, T, r, sigma, n, option_type='call', exercise_type='american')[0, 0]\n",
    "put_without_div = binomial_tree(S, K, T, r, sigma, n, option_type='put', exercise_type='american')[0, 0]\n",
    "call_with_div = binomial_tree(S, K, T, r, sigma, n, option_type='call', exercise_type='american', div_date=div_date, div_amt=div_amt)[0, 0]\n",
    "put_with_div = binomial_tree(S, K, T, r, sigma, n, option_type='put', exercise_type='american', div_date=div_date, div_amt=div_amt)[0, 0]\n",
    "\n",
    "print(\"American Call Option without Dividends:\", call_without_div)\n",
    "print(\"American Put Option without Dividends:\", put_without_div)\n",
    "print(\"American Call Option with Dividends:\", call_with_div)\n",
    "print(\"American Put Option with Dividends:\", put_with_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call Option Greeks:\n",
      "       Call without div  Call with div\n",
      "Delta          0.082067       0.072438\n",
      "Gamma          0.016219       0.014888\n",
      "Theta         -7.663421      -6.868668\n",
      "Vega           7.031265       5.894682\n",
      "Rho            1.080959       0.917994\n",
      "\n",
      "Put Option Greeks:\n",
      "       Put without div  Put with div\n",
      "Delta        -0.957268     -0.964653\n",
      "Gamma         0.020478      0.014834\n",
      "Theta        -2.258358     -1.720999\n",
      "Vega          3.751046      2.939957\n",
      "Rho          -2.847535     -2.823484\n"
     ]
    }
   ],
   "source": [
    "# calculate greeks\n",
    "call_greeks_without_div = binomial_tree_greeks(S, K, T, r, sigma, n, option_type='call', exercise_type='american')\n",
    "put_greeks_without_div = binomial_tree_greeks(S, K, T, r, sigma, n, option_type='put', exercise_type='american')\n",
    "call_greeks_with_div = binomial_tree_greeks(S, K, T, r, sigma, n, option_type='call', exercise_type='american', div_date=div_date, div_amt=div_amt)\n",
    "put_greeks_with_div = binomial_tree_greeks(S, K, T, r, sigma, n, option_type='put', exercise_type='american', div_date=div_date, div_amt=div_amt)\n",
    "\n",
    "# create dataframe for greeks\n",
    "greek_labels = ['Delta', 'Gamma', 'Theta', 'Vega', 'Rho']\n",
    "call_greeks = pd.DataFrame({'Call without div': call_greeks_without_div, 'Call with div': call_greeks_with_div}, index=greek_labels)\n",
    "put_greeks = pd.DataFrame({'Put without div': put_greeks_without_div, 'Put with div': put_greeks_with_div}, index=greek_labels)\n",
    "\n",
    "# display greeks dataframes\n",
    "print('Call Option Greeks:')\n",
    "print(call_greeks)\n",
    "\n",
    "print('\\nPut Option Greeks:')\n",
    "print(put_greeks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta Call with Dividend:  -0.06606797048803119\n",
      "Delta Put with Dividend:  0.9604827031086066\n"
     ]
    }
   ],
   "source": [
    "# Calculate the sensitivity of the call and put to a change in dividend amount\n",
    "Delta_call_dividend = (call_with_div - call_without_div) / div_amt\n",
    "Delta_put_dividend = (put_with_div - put_without_div) / div_amt\n",
    "\n",
    "print(\"Delta Call with Dividend: \", Delta_call_dividend)\n",
    "print(\"Delta Put with Dividend: \", Delta_put_dividend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_sharpe_ratio_weights(cov_m, exp_returns, rf):\n",
    "    num_stocks = len(exp_returns)\n",
    "    \n",
    "    # Define the Sharpe Ratio objective function to be minimized\n",
    "    def neg_sharpe_ratio(weights):\n",
    "        port_return = np.dot(weights, exp_returns)\n",
    "        port_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_m, weights)))\n",
    "        sharpe_ratio = (port_return - rf) / port_volatility\n",
    "        return -sharpe_ratio\n",
    "    \n",
    "    # Define the constraints\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1}) # The sum of the weights must be 1\n",
    "    bounds = tuple([(0, 1) for i in range(num_stocks)]) # The weights must be between 0 and 1\n",
    "    \n",
    "    # Find the portfolio weights that maximize the Sharpe Ratio\n",
    "    initial_weights = np.ones(num_stocks) / num_stocks # Start with equal weights\n",
    "    opt_results = minimize(neg_sharpe_ratio, initial_weights, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return opt_results.x.round(4), opt_results.fun \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all data\n",
    "ff3 = pd.read_csv(\"F-F_Research_Data_Factors_daily.CSV\")\n",
    "mom = pd.read_csv(\"F-F_Momentum_Factor_daily.CSV\")\n",
    "# prices = pd.read_csv(\"DailyPrices.csv\")\n",
    "# returns = calc_return.return_calculate(prices, date_column=\"Date\")\n",
    "rf = 0.0025\n",
    "returns = pd.read_csv('DailyReturn.csv')\n",
    "# Join the FF3 data with the Momentum Data\n",
    "ffData = pd.merge(ff3, mom, on=\"Date\")\n",
    "ffData.rename(columns={ffData.columns[-1]: \"Mom\"}, inplace=True)\n",
    "ffData.iloc[:, 1:] = ffData.iloc[:, 1:].div(100)\n",
    "ffData['Date'] = pd.to_datetime(ffData['Date'].astype(str), format=\"%Y%m%d\")\n",
    "\n",
    "returns['Date'] = pd.to_datetime(returns['Date'], format=\"%m/%d/%Y\")\n",
    "# Our 20 stocks\n",
    "# stocks = ['AAPL', 'META', 'UNH', 'MA', 'MSFT', 'NVDA', 'HD', 'PFE', 'AMZN', 'BRK-B', 'PG', 'XOM', 'TSLA', 'JPM', 'V', 'DIS', 'GOOGL', 'JNJ', 'BAC', 'CSCO']\n",
    "stocks = ['AAPL', 'MSFT', 'BRK-B', 'CSCO', 'JNJ']\n",
    "# Data set of all stock returns and FF3+1 returns\n",
    "to_reg = pd.merge(returns[['Date'] + stocks], ffData, on=\"Date\")\n",
    "\n",
    "xnames = [\"Mkt-RF\", \"SMB\", \"HML\", \"Mom\"]\n",
    "\n",
    "# OLS Regression for all Stocks\n",
    "X = np.column_stack((np.ones(len(to_reg)), to_reg[xnames].values))\n",
    "Y = to_reg[stocks].values\n",
    "\n",
    "Betas = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "Betas = Betas.T\n",
    "\n",
    "# Calculate the means of the last 10 years of factor returns\n",
    "# adding the 0.0 at the front to 0 out the fitted alpha in the next step\n",
    "means = np.concatenate(([0.0], ffData.loc[ffData['Date'] >= datetime(2013, 2, 9), xnames].mean()))\n",
    "\n",
    "# Discrete Returns, convert to Log Returns and scale to 1 year\n",
    "stockMeans = np.log(1 + Betas @ means) * 255 + rf\n",
    "covar = np.cov(np.log(1.0 + Y.T)) * 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe ratio is: 1.002075889964526\n"
     ]
    }
   ],
   "source": [
    "weights, sharpe = max_sharpe_ratio_weights(covar, stockMeans, rf)\n",
    "print(\"Sharpe ratio is:\", -sharpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1013, 0.223 , 0.3998, 0.0789, 0.1969])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_weights = np.array(weights)\n",
    "portfolio_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11751080534238349\n"
     ]
    }
   ],
   "source": [
    "expected_return = portfolio_weights.dot(stockMeans)\n",
    "print(expected_return)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.88941679e-02 -2.43392445e-02 -1.18470859e-02 -2.65645530e-02\n",
      "  -4.40884054e-03]\n",
      " [-2.10247564e-02  2.24679386e-03 -1.72968524e-02 -1.38958312e-02\n",
      "  -3.11196711e-03]\n",
      " [-1.03471555e-02 -5.70329297e-03 -1.18824146e-02 -1.39219011e-02\n",
      "  -7.98415795e-03]\n",
      " [-1.27650431e-02 -1.84681547e-02 -1.86167931e-02 -2.41047168e-02\n",
      "  -2.29956273e-03]\n",
      " [-4.86436920e-03  1.14851725e-03 -4.88169188e-03  3.88147495e-03\n",
      "  -1.15242108e-02]\n",
      " [-1.13846517e-02 -2.65883829e-02  1.13916665e-02 -1.38840241e-02\n",
      "   2.85942352e-02]\n",
      " [-5.63302820e-04  2.84931734e-02  6.73852660e-03 -1.39012473e-02\n",
      "   4.47418541e-03]\n",
      " [-2.94313383e-03  1.05489995e-02 -5.14129518e-03 -1.28321521e-02\n",
      "   1.31250009e-02]\n",
      " [ 6.97776174e-02  2.80817224e-02  1.69986699e-02  1.81252658e-02\n",
      "   7.03435615e-03]\n",
      " [ 2.61257461e-02  8.82371531e-03  3.83493136e-04  1.07888867e-03\n",
      "   2.91053112e-03]\n",
      " [-9.72658871e-04 -7.13873818e-03  3.00300950e-03 -5.38888110e-03\n",
      "  -8.18384317e-03]\n",
      " [ 7.04429943e-03  1.52220984e-02  1.79641201e-02  1.44482394e-02\n",
      "   1.10603926e-02]\n",
      " [-1.67197733e-02 -3.89522729e-02 -1.36733258e-02 -1.72689520e-02\n",
      "  -5.78675016e-05]\n",
      " [-1.67937232e-03  1.55684866e-02 -7.61415448e-04 -9.05778969e-04\n",
      "  -6.54083336e-03]\n",
      " [-4.23455539e-03 -1.63103958e-02  4.82561366e-03  3.62574783e-04\n",
      "  -3.32116559e-03]\n",
      " [ 1.84667245e-02  1.19953081e-02  1.55761014e-02  3.08142117e-03\n",
      "   2.63064545e-03]\n",
      " [ 8.29375384e-03  2.18347224e-02  2.92434978e-03  1.71666245e-02\n",
      "  -1.16485500e-04]\n",
      " [-2.35988429e-02 -2.83729888e-02 -7.84787816e-03 -2.52265407e-02\n",
      "  -1.20707438e-02]\n",
      " [-2.02184296e-02 -2.42741096e-02 -2.21976235e-03 -1.76780940e-02\n",
      "  -1.00931867e-02]\n",
      " [ 1.42318549e-03 -1.35573262e-04 -1.52284758e-02 -1.33581071e-02\n",
      "  -1.25812468e-02]\n",
      " [ 2.31524626e-02  1.85423621e-02  6.10924337e-03  2.04964272e-02\n",
      "   1.03260180e-02]\n",
      " [-1.38891145e-03 -1.16727028e-03 -1.73946230e-03 -3.68527732e-04\n",
      "  -5.97619655e-04]\n",
      " [-2.12691854e-02 -2.92821002e-02 -6.65295752e-03  2.80184332e-02\n",
      "  -6.10017211e-03]\n",
      " [-9.35576713e-03 -9.63099059e-03  3.98660516e-03  2.58203156e-02\n",
      "  -1.07188515e-02]\n",
      " [-1.78122890e-02 -7.29316171e-04 -2.03298610e-03 -1.59063104e-02\n",
      "  -1.35896302e-02]\n",
      " [-2.58641664e-02 -2.58932711e-02 -1.32735356e-02 -3.30373008e-02\n",
      "   4.96475118e-04]\n",
      " [ 1.66801892e-02  5.10936153e-02 -5.51627812e-03  5.32698393e-03\n",
      "  -1.91043418e-02]\n",
      " [ 1.29654721e-02  9.23317844e-03  3.55520664e-02  2.39357025e-02\n",
      "   4.97028016e-02]\n",
      " [ 1.63778581e-03  4.97800616e-03  6.92276052e-03 -4.81800491e-03\n",
      "  -8.61441566e-03]]\n",
      "                Value      AAPL      MSFT     BRK-B      CSCO       JNJ  \\\n",
      "0         TotalReturn -0.044720 -0.034791 -0.008268 -0.091102 -0.013189   \n",
      "1  Return Attribution -0.004626 -0.007543 -0.003384 -0.007328 -0.002498   \n",
      "2     Vol Attribution  0.001576  0.003403  0.004226  0.000859  0.001647   \n",
      "\n",
      "   Portfolio  \n",
      "0  -0.025479  \n",
      "1  -0.025479  \n",
      "2   0.011714  \n"
     ]
    }
   ],
   "source": [
    "# Get Updated Prices\n",
    "stocks = ['AAPL', 'MSFT', 'BRK-B', 'CSCO', 'JNJ']\n",
    "portfolio_weights = np.array([0.1013, 0.223 , 0.3998, 0.0789, 0.1969])\n",
    "updated = pd.read_csv(\"/Users/ansel_li/FinTech-545-Spring2023/Week08/updated_prices.csv\")\n",
    "updated[\"Date\"] = pd.to_datetime(updated.Date, format=\"%m/%d/%Y\")\n",
    "upReturns = calc_return.return_calculate(updated, date_column=\"Date\")\n",
    "\n",
    "# Calculate portfolio return and updated weights for each day\n",
    "n = upReturns.shape[0]\n",
    "m = len(stocks)\n",
    "\n",
    "pReturn = np.empty(n)\n",
    "weights = np.empty((n, len(portfolio_weights)))\n",
    "lastW = portfolio_weights.copy()\n",
    "matReturns = upReturns[stocks].values\n",
    "print(matReturns)\n",
    "for i in range(n):\n",
    "    # Save Current Weights in Matrix\n",
    "    weights[i, :] = lastW\n",
    "\n",
    "    # Update Weights by return\n",
    "    lastW = lastW * (1.0 + matReturns[i, :])\n",
    "\n",
    "    # Portfolio return is the sum of the updated weights\n",
    "    pR = lastW.sum()\n",
    "\n",
    "    # Normalize the weights back so sum = 1\n",
    "    lastW = lastW / pR\n",
    "\n",
    "    # Store the return\n",
    "    pReturn[i] = pR - 1\n",
    "# Set the portfolio return in the Update Return DataFrame\n",
    "upReturns[\"Portfolio\"] = pReturn\n",
    "\n",
    "# Calculate the total return\n",
    "totalRet = np.exp(np.sum(np.log(pReturn + 1))) - 1\n",
    "\n",
    "# Calculate the Carino K\n",
    "k = np.log(totalRet + 1) / totalRet\n",
    "\n",
    "# Carino k_t is the ratio scaled by 1/K\n",
    "carinoK = np.log(1.0 + pReturn) / pReturn / k\n",
    "\n",
    "# Calculate the return attribution\n",
    "attrib = pd.DataFrame(matReturns * weights * carinoK[:, np.newaxis], columns=stocks)\n",
    "\n",
    "# Set up a DataFrame for output\n",
    "Attribution = pd.DataFrame({\"Value\": [\"TotalReturn\", \"Return Attribution\"]})\n",
    "\n",
    "# Loop over the stocks\n",
    "for s in stocks + [\"Portfolio\"]:\n",
    "    # Total Stock return over the period\n",
    "    tr = np.exp(np.sum(np.log(upReturns[s] + 1))) - 1\n",
    "\n",
    "    # Attribution Return (total portfolio return if we are updating the portfolio column)\n",
    "    atr = tr if s == \"Portfolio\" else attrib[s].sum()\n",
    "\n",
    "    # Set the values\n",
    "    Attribution[s] = [tr, atr]\n",
    "\n",
    "# Realized Volatility Attribution\n",
    "\n",
    "# Y is our stock returns scaled by their weight at each time\n",
    "Y = matReturns * weights\n",
    "\n",
    "# Set up X with the Portfolio Return\n",
    "X = np.column_stack((np.ones(n), pReturn))\n",
    "\n",
    "# Calculate the Beta and discard the intercept\n",
    "B = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "B = B[1, :]\n",
    "\n",
    "# Component SD is Beta times the standard Deviation of the portfolio\n",
    "cSD = B * np.std(pReturn)\n",
    "\n",
    "# Add the Vol attribution to the output\n",
    "vol_attrib = pd.DataFrame({\"Value\": [\"Vol Attribution\"], **{stocks[i]: [cSD[i]] for i in range(len(stocks))}, \"Portfolio\": [np.std(pReturn)]})\n",
    "\n",
    "Attribution = pd.concat([Attribution, vol_attrib], ignore_index=True)\n",
    "\n",
    "print(Attribution)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Stock    Weight       cEr\n",
      "0   AAPL  0.100792  0.014285\n",
      "1   MSFT  0.209487  0.035649\n",
      "2  BRK-B  0.438283  0.048322\n",
      "3   CSCO  0.081217  0.011085\n",
      "4    JNJ  0.170222  0.012090\n",
      "                Value    Mkt_RF       SMB       HML       Mom     Alpha  \\\n",
      "0         TotalReturn -0.058005 -0.001108  0.020274  0.008215  0.018044   \n",
      "1  Return Attribution -0.044562  0.000103  0.002425 -0.000610  0.017580   \n",
      "2     Vol Attribution  0.009775 -0.000109 -0.000715  0.000127  0.002640   \n",
      "\n",
      "   Portfolio  \n",
      "0  -0.025063  \n",
      "1  -0.025063  \n",
      "2   0.011718  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Read CSV files\n",
    "ff3 = pd.read_csv('F-F_Research_Data_Factors_daily.CSV')\n",
    "mom = pd.read_csv('F-F_Momentum_Factor_daily.CSV')\n",
    "returns = pd.read_csv('DailyReturn.csv')\n",
    "\n",
    "# Join the FF3 data with the Momentum Data\n",
    "ffData = ff3.merge(mom, on='Date')\n",
    "ffData.rename(columns={ffData.columns[-1]: 'Mom', 'Mkt-RF': 'Mkt_RF'}, inplace=True)\n",
    "ffData.iloc[:, 1:] = ffData.iloc[:, 1:].values / 100\n",
    "ffData['Date'] = pd.to_datetime(ffData['Date'], format='%Y%m%d')\n",
    "\n",
    "returns['Date'] = pd.to_datetime(returns['Date'], format='%m/%d/%Y')\n",
    "\n",
    "# Join the FF3+1 to Stock data - filter to stocks we want\n",
    "stocks = ['AAPL', 'MSFT', 'BRK-B', 'CSCO', 'JNJ']\n",
    "to_reg = returns[['Date', 'SPY'] + stocks].merge(ffData, on='Date')\n",
    "\n",
    "xnames = ['Mkt_RF', 'SMB', 'HML', 'Mom']\n",
    "\n",
    "# OLS Regression for all Stocks\n",
    "X = np.hstack([np.ones((len(to_reg), 1)), to_reg[xnames].values])\n",
    "Y = to_reg[stocks].values\n",
    "Betas = (np.linalg.inv(X.T @ X) @ X.T @ Y).T[:, 1:]\n",
    "\n",
    "max_dt = max(to_reg['Date'])\n",
    "min_dt = max_dt - pd.DateOffset(years=10)\n",
    "to_mean = ffData[(ffData['Date'] >= min_dt) & (ffData['Date'] <= max_dt)]\n",
    "\n",
    "# Historic daily factor returns\n",
    "exp_Factor_Return = to_mean[xnames].mean().values\n",
    "expFactorReturns = pd.DataFrame({'Factor': xnames, 'Er': exp_Factor_Return})\n",
    "\n",
    "# Scale returns and covariance to geometric yearly numbers\n",
    "stockMeans = np.log(1 + Betas @ exp_Factor_Return) * 255\n",
    "covar = np.cov(np.log(1 + Y), rowvar=False) * 255\n",
    "\n",
    "def sr(w):\n",
    "    _w = np.array(w)\n",
    "    m = _w.T @ stockMeans - 0.0025\n",
    "    s = np.sqrt(_w.T @ covar @ _w)\n",
    "    return -(m / s)\n",
    "\n",
    "n = len(stocks)\n",
    "x0 = np.ones(n) / n\n",
    "bounds = [(0, None) for _ in range(n)]\n",
    "constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "\n",
    "result = minimize(sr, x0, bounds=bounds, constraints=constraints)\n",
    "w = result.x / np.sum(result.x)\n",
    "\n",
    "OptWeights = pd.DataFrame({'Stock': stocks, 'Weight': w, 'cEr': stockMeans * w})\n",
    "print(OptWeights)\n",
    "\n",
    "# Get Updated Prices\n",
    "updated = pd.read_csv(\"updated_prices.csv\")\n",
    "updated['Date'] = pd.to_datetime(updated['Date'], format='%m/%d/%Y')\n",
    "\n",
    "# Define a function for calculating returns\n",
    "def return_calculate(df, dateColumn=\"Date\"):\n",
    "    df = df.sort_values(by=dateColumn)\n",
    "    returns = df.iloc[:, 1:].pct_change().dropna()\n",
    "    returns[dateColumn] = df[dateColumn]\n",
    "    return returns\n",
    "\n",
    "upReturns = return_calculate(updated, dateColumn=\"Date\")\n",
    "\n",
    "upFf3 = pd.read_csv(\"updated_F-F_Research_Data_Factors_daily.CSV\")\n",
    "upMom = pd.read_csv(\"updated_F-F_Momentum_Factor_daily.CSV\")\n",
    "upFfData = upFf3.merge(upMom, on='Date')\n",
    "upFfData.rename(columns={upFfData.columns[-1]: 'Mom', 'Mkt-RF': 'Mkt_RF'}, inplace=True)\n",
    "upFfData[upFfData.columns[1:]] = upFfData[upFfData.columns[1:]] / 100\n",
    "upFfData['Date'] = pd.to_datetime(upFfData['Date'], format='%Y%m%d')\n",
    "\n",
    "upFfData = pd.concat([ffData, upFfData], ignore_index=True)\n",
    "upFfData.drop(columns=['RF'], inplace=True)\n",
    "\n",
    "# Filter the FF returns to just the Stock return data\n",
    "upFfData = upReturns.merge(upFfData, on='Date')[['Date'] + xnames]\n",
    "\n",
    "# Calculate portfolio return and updated weights for each day\n",
    "n = len(upReturns)\n",
    "m = len(stocks)\n",
    "\n",
    "pReturn = np.zeros(n)\n",
    "residReturn = np.zeros(n)\n",
    "weights = np.zeros((n, len(w)))\n",
    "factorWeights = np.zeros((n, len(xnames)))\n",
    "lastW = w.copy()\n",
    "matReturns = upReturns[stocks].values\n",
    "ffReturns = upFfData[xnames].values\n",
    "\n",
    "for i in range(n):\n",
    "    # Save Current Weights in Matrix\n",
    "    weights[i, :] = lastW\n",
    "\n",
    "    # Factor Weight\n",
    "    factorWeights[i, :] = np.sum(Betas * lastW[:, np.newaxis], axis=0)\n",
    "\n",
    "\n",
    "    # Update Weights by return\n",
    "    lastW = lastW * (1.0 + matReturns[i, :])\n",
    "\n",
    "    # Portfolio return is the sum of the updated weights\n",
    "    pR = np.sum(lastW)\n",
    "    # Normalize the weights back so sum = 1\n",
    "    lastW = lastW / pR\n",
    "    # Store the return\n",
    "    pReturn[i] = pR - 1\n",
    "\n",
    "    # Residual\n",
    "    residReturn[i] = (pR - 1) - factorWeights[i, :].T @ ffReturns[i, :]\n",
    "\n",
    "\n",
    "\n",
    "# Set the portfolio return in the Update Return DataFrame\n",
    "upFfData['Alpha'] = residReturn\n",
    "upFfData['Portfolio'] = pReturn\n",
    "\n",
    "# Calculate the total return\n",
    "totalRet = np.exp(np.sum(np.log(pReturn + 1))) - 1\n",
    "# Calculate the Carino K\n",
    "k = np.log(totalRet + 1) / totalRet\n",
    "\n",
    "# Carino k_t is the ratio scaled by 1/K\n",
    "carinoK = np.log(1.0 + pReturn) / pReturn / k\n",
    "# Calculate the return attribution\n",
    "attrib = pd.DataFrame(ffReturns * factorWeights * carinoK[:, np.newaxis], columns=xnames)\n",
    "attrib['Alpha'] = residReturn * carinoK\n",
    "\n",
    "# Set up a DataFrame for output\n",
    "Attribution = pd.DataFrame({'Value': [\"TotalReturn\", \"Return Attribution\"]})\n",
    "\n",
    "newFactors = xnames + ['Alpha']\n",
    "# Loop over the factors\n",
    "for s in newFactors + ['Portfolio']:\n",
    "    # Total Stock return over the period\n",
    "    tr = np.exp(np.sum(np.log(upFfData[s] + 1))) - 1\n",
    "    # Attribution Return (total portfolio return if we are updating the portfolio column)\n",
    "    atr = tr if s == 'Portfolio' else attrib[s].sum()\n",
    "    # Set the values\n",
    "    Attribution[s] = [tr, atr]\n",
    "\n",
    "# Check that the attribution sums back to the total Portfolio return\n",
    "assert np.isclose(Attribution.loc[1, newFactors].sum(), totalRet)\n",
    "\n",
    "# Realized Volatility Attribution\n",
    "\n",
    "# Y is our stock returns scaled by their weight at each time\n",
    "Y = np.hstack((ffReturns * factorWeights, residReturn[:, np.newaxis]))\n",
    "# Set up X with the Portfolio Return\n",
    "X = np.hstack((np.ones((len(pReturn), 1)), pReturn[:, np.newaxis]))\n",
    "# Calculate the Beta and discard the intercept\n",
    "B = (np.linalg.inv(X.T @ X) @ X.T @ Y)[1, :]\n",
    "# Component SD is Beta times the standard deviation of the portfolio\n",
    "cSD = B * np.std(pReturn)\n",
    "\n",
    "# Check that the sum of component SD is equal to the portfolio SD\n",
    "assert np.isclose(cSD.sum(), np.std(pReturn))\n",
    "\n",
    "vol_attrib_df = pd.DataFrame(\n",
    "    {\"Value\": \"Vol Attribution\", **{newFactors[i]: cSD[i] for i in range(len(newFactors))}, \"Portfolio\": np.std(pReturn)},\n",
    "    index=[2]\n",
    ")\n",
    "\n",
    "Attribution = pd.concat([Attribution, vol_attrib_df], ignore_index=True)\n",
    "\n",
    "\n",
    "print(Attribution)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Stock    Weight       cEr       CES\n",
      "0   AAPL  0.189243  0.000021  0.237646\n",
      "1   MSFT  0.190263  0.027953  0.238429\n",
      "2  BRK-B  0.208299 -0.021989  0.237438\n",
      "3   CSCO  0.179592 -0.017450  0.237496\n",
      "4    JNJ  0.232603  0.013840  0.238174\n",
      "   Stock    Weight       cEr       CSD\n",
      "0   AAPL  0.154203  0.000017  0.022688\n",
      "1   MSFT  0.142566  0.020945  0.022688\n",
      "2  BRK-B  0.265160 -0.027992  0.022688\n",
      "3   CSCO  0.150786 -0.014651  0.022688\n",
      "4    JNJ  0.287285  0.017094  0.022688\n",
      "AAPL -- df: 1970111.246238185, loc: -4.696186663373325e-07, scale: 0.015911523598135014\n",
      "MSFT -- df: 4.5964540434780785, loc: 0.00037631927018799157, scale: 0.01240097061462394\n",
      "BRK-B -- df: 21.7484660281291, loc: -2.982870119172333e-05, scale: 0.008997359286131264\n",
      "CSCO -- df: 4.542918915808315, loc: 0.0002855876803817062, scale: 0.010920213502832945\n",
      "JNJ -- df: 9.428619560362845, loc: 9.002379518935252e-05, scale: 0.008225160760266727\n"
     ]
    }
   ],
   "source": [
    "ff3 = pd.read_csv(\"F-F_Research_Data_Factors_daily.CSV\")\n",
    "mom = pd.read_csv(\"F-F_Momentum_Factor_daily.CSV\")\n",
    "returns = pd.read_csv(\"DailyReturn.csv\")\n",
    "\n",
    "ffData = pd.merge(ff3, mom, on=\"Date\")\n",
    "ffData.rename(columns={ffData.columns[-1]: \"Mom\", \"Mkt-RF\": \"Mkt_RF\"}, inplace=True)\n",
    "ffData.iloc[:, 1:] = ffData.iloc[:, 1:] / 100\n",
    "ffData[\"Date\"] = pd.to_datetime(ffData[\"Date\"], format=\"%Y%m%d\")\n",
    "\n",
    "returns[\"Date\"] = pd.to_datetime(returns[\"Date\"], format=\"%m/%d/%Y\")\n",
    "\n",
    "stocks = [\"AAPL\", \"MSFT\", \"BRK-B\", \"CSCO\", \"JNJ\"]\n",
    "to_reg = pd.merge(returns[[\"Date\", \"SPY\"] + stocks], ffData, on=\"Date\")\n",
    "\n",
    "xnames = [\"Mkt_RF\", \"SMB\", \"HML\", \"Mom\"]\n",
    "\n",
    "X = np.column_stack((np.ones(len(to_reg)), to_reg[xnames].values))\n",
    "Y = to_reg[stocks].values\n",
    "Betas = np.linalg.inv(X.T @ X) @ X.T @ Y\n",
    "resid = Y - X @ Betas.T\n",
    "Betas = Betas[:, 1:]\n",
    "\n",
    "max_dt = to_reg[\"Date\"].max()\n",
    "min_dt = max_dt - timedelta(days=365*10)\n",
    "to_mean = ffData[(ffData[\"Date\"] >= min_dt) & (ffData[\"Date\"] <= max_dt)]\n",
    "\n",
    "exp_Factor_Return = to_mean[xnames].mean().values\n",
    "expFactorReturns = pd.DataFrame({\"Factor\": xnames, \"Er\": exp_Factor_Return})\n",
    "\n",
    "stockMeans = np.log(1 + Betas @ exp_Factor_Return) * 255\n",
    "covar = np.cov(np.log(1 + Y), rowvar=False) * 255\n",
    "\n",
    "def pvol(w, covar):\n",
    "    return np.sqrt(w.T @ covar @ w)\n",
    "\n",
    "def pCSD(w, covar):\n",
    "    pVol = pvol(w, covar)\n",
    "    csd = w * (covar @ w) / pVol\n",
    "    return csd\n",
    "\n",
    "def sseCSD(w, covar):\n",
    "    csd = pCSD(w, covar)\n",
    "    mCSD = np.mean(csd)\n",
    "    dCsd = csd - mCSD\n",
    "    se = dCsd * dCsd\n",
    "    return 1.0e5 * np.sum(se)\n",
    "\n",
    "n = len(stocks)\n",
    "\n",
    "cons = ({'type': 'eq', 'fun': lambda w: 1.0 - np.sum(w)})\n",
    "bnds = [(0, None) for _ in range(n)]\n",
    "initial_guess = np.array([1/n] * n)\n",
    "\n",
    "res = minimize(sseCSD, initial_guess, args=(covar,), constraints=cons, bounds=bnds)\n",
    "w = res.x\n",
    "\n",
    "RPWeights = pd.DataFrame({\"Stock\": stocks, \"Weight\": w, \"cEr\": stockMeans * w, \"CSD\": pCSD(w, covar)})\n",
    "\n",
    "m = Y.mean(axis=0)\n",
    "Y = Y - m\n",
    "\n",
    "models = [t.fit(Y[:, i]) for i in range(Y.shape[1])]\n",
    "U = np.column_stack([(Y[:, i] - loc) / scale for i, (df, loc, scale) in enumerate(models)])\n",
    "\n",
    "\n",
    "nSim = 5000\n",
    "\n",
    "corsp = spearmanr(U).correlation\n",
    "_simU = norm.cdf(multivariate_normal.rvs(mean=np.zeros(n), cov=corsp, size=nSim)).T\n",
    "simReturn = np.empty_like(_simU)\n",
    "\n",
    "for i in range(n):\n",
    "    df, loc, scale = models[i]\n",
    "    simReturn[:, i] = t.ppf(_simU[:, i], df=df, loc=loc, scale=scale)\n",
    "\n",
    "def _ES(w):\n",
    "    x = np.array(w)\n",
    "    r = np.sum(simReturn * x[:, np.newaxis], axis=0)\n",
    "    return VaR.ES(r)\n",
    "\n",
    "def CES(w):\n",
    "    x = np.array(w)\n",
    "    n = len(x)\n",
    "    ces = np.zeros(n)\n",
    "    es = _ES(x)\n",
    "    e = 1e-6\n",
    "    for i in range(n):\n",
    "        old = x[i]\n",
    "        x[i] = x[i] + e\n",
    "        ces[i] = old * (_ES(x) - es) / e\n",
    "        x[i] = old\n",
    "    return ces\n",
    "\n",
    "def SSE_CES(w):\n",
    "    ces = CES(w)\n",
    "    ces = ces - np.mean(ces)\n",
    "    return 1e3 * (ces.T @ ces)\n",
    "\n",
    "res = minimize(SSE_CES, initial_guess, constraints=cons, bounds=bnds)\n",
    "w = res.x\n",
    "\n",
    "ES_RPWeights = pd.DataFrame({\"Stock\": stocks, \"Weight\": w, \"cEr\": stockMeans * w, \"CES\": CES(w)})\n",
    "print(ES_RPWeights)\n",
    "print(RPWeights)\n",
    "\n",
    "for i, stock in enumerate(stocks):\n",
    "    df, loc, scale = models[i]\n",
    "    print(f\"{stock} -- df: {df}, loc: {loc}, scale: {scale}\")\n",
    "\n",
    "# print(corsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "ff3 = pd.read_csv(\"F-F_Research_Data_Factors_daily.CSV\")\n",
    "mom = pd.read_csv(\"F-F_Momentum_Factor_daily.CSV\")\n",
    "returns = pd.read_csv(\"DailyReturn.csv\")\n",
    "\n",
    "ffData = pd.merge(ff3, mom, on=\"Date\")\n",
    "ffData.rename(columns={ffData.columns[-1]: \"Mom\", \"Mkt-RF\": \"Mkt_RF\"}, inplace=True)\n",
    "ffData.iloc[:, 1:] = ffData.iloc[:, 1:] / 100\n",
    "ffData[\"Date\"] = pd.to_datetime(ffData[\"Date\"], format=\"%Y%m%d\")\n",
    "\n",
    "returns[\"Date\"] = pd.to_datetime(returns[\"Date\"], format=\"%m/%d/%Y\")\n",
    "\n",
    "stocks = [\"AAPL\", \"MSFT\", \"BRK-B\", \"CSCO\", \"JNJ\"]\n",
    "to_reg = pd.merge(returns[[\"Date\", \"SPY\"] + stocks], ffData, on=\"Date\")\n",
    "\n",
    "xnames = ['Mkt_RF', 'SMB', 'HML', 'Mom']\n",
    "\n",
    "# OLS Regression for all Stocks\n",
    "X = to_reg[xnames].values\n",
    "Y = to_reg[stocks].values\n",
    "\n",
    "Betas = []\n",
    "for stock in stocks:\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X, to_reg[stock].values)\n",
    "    Betas.append(lr.coef_)\n",
    "\n",
    "Betas = np.array(Betas)\n",
    "\n",
    "max_dt = to_reg[\"Date\"].max()\n",
    "min_dt = max_dt - pd.DateOffset(years=10)\n",
    "to_mean = ffData[(ffData[\"Date\"] >= min_dt) & (ffData[\"Date\"] <= max_dt)]\n",
    "\n",
    "# Historic daily factor returns\n",
    "exp_Factor_Return = to_mean[xnames].mean().values\n",
    "\n",
    "# Scale returns and covariance to geometric yearly numbers\n",
    "stockMeans = np.log(1 + Betas @ exp_Factor_Return) * 255\n",
    "covar = np.cov(np.log(1 + Y), rowvar=False) * 255\n",
    "\n",
    "# Portfolio Volatility function\n",
    "def pvol(w):\n",
    "    return np.sqrt(w @ covar @ w)\n",
    "\n",
    "# Component Standard Deviation function\n",
    "def pCSD(w):\n",
    "    p_vol = pvol(w)\n",
    "    return w * (covar @ w) / p_vol\n",
    "\n",
    "# Sum Square Error of cSD\n",
    "def sseCSD(w):\n",
    "    csd = pCSD(w)\n",
    "    mCSD = np.sum(csd) / len(stocks)\n",
    "    dCsd = csd - mCSD\n",
    "    se = dCsd * dCsd\n",
    "    return 1e5 * np.sum(se)\n",
    "\n",
    "# Optimize to find Risk Parity weights\n",
    "n = len(stocks)\n",
    "initial_weights = np.ones(n) / n\n",
    "constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "bounds = [(0, None) for _ in range(n)]\n",
    "\n",
    "result = minimize(sseCSD, initial_weights, constraints=constraints, bounds=bounds)\n",
    "optimized_weights = result.x\n",
    "\n",
    "RPWeights = pd.DataFrame({'Stock': stocks, 'Weight': optimized_weights, 'cEr': stockMeans * optimized_weights, 'CSD': pCSD(optimized_weights)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Stock    Weight       cEr       CES\n",
      "0   AAPL  0.147450  0.020898  0.001723\n",
      "1   MSFT  0.140376  0.023888  0.001714\n",
      "2  BRK-B  0.324363  0.035762  0.001759\n",
      "3   CSCO  0.168639  0.023017  0.001727\n",
      "4    JNJ  0.219172  0.015567  0.001714\n",
      "   Stock    Weight       cEr       CSD\n",
      "0   AAPL  0.154203  0.021855  0.022688\n",
      "1   MSFT  0.142566  0.024261  0.022688\n",
      "2  BRK-B  0.265160  0.029235  0.022688\n",
      "3   CSCO  0.150786  0.020581  0.022688\n",
      "4    JNJ  0.287285  0.020405  0.022688\n",
      "Degrees of freedom for all stocks:\n",
      "AAPL : 3209646.862325821\n",
      "MSFT : 4.596292767770695\n",
      "BRK-B : 21.748436506065993\n",
      "CSCO : 4.5428908272455\n",
      "JNJ : 9.428487611937966\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Function for fitting t-distribution to the data\n",
    "def fit_general_t(data):\n",
    "    params = stats.t.fit(data)\n",
    "    fitted_data = stats.t.rvs(params[0], params[1], params[2], size=len(data))\n",
    "    return fitted_data, params\n",
    "\n",
    "# Fit t-distributions to the returns\n",
    "fitted_returns = []\n",
    "params_list = []\n",
    "for stock in stocks:\n",
    "    fitted_data, params = fit_general_t(Y[:, stocks.index(stock)])\n",
    "    fitted_returns.append(fitted_data)\n",
    "    params_list.append(params)\n",
    "\n",
    "U = np.column_stack(fitted_returns)\n",
    "\n",
    "# Gaussian Copula simulation\n",
    "nSim = 5000\n",
    "corsp = stats.spearmanr(U).correlation\n",
    "_simU = stats.norm.cdf(np.random.multivariate_normal(np.zeros(n), corsp, nSim))\n",
    "simReturn = np.zeros_like(_simU)\n",
    "\n",
    "for i in range(n):\n",
    "    simReturn[:, i] = stats.t.ppf(_simU[:, i], *params_list[i])\n",
    "\n",
    "# Internal ES function\n",
    "def _ES(w):\n",
    "    r = simReturn @ w\n",
    "    return VaR.ES(r)\n",
    "\n",
    "# Function for the component ES\n",
    "def CES(w):\n",
    "    n = len(w)\n",
    "    ces = np.zeros(n)\n",
    "    es = _ES(w)\n",
    "    e = 1e-6\n",
    "    for i in range(n):\n",
    "        old = w[i]\n",
    "        w[i] = w[i] + e\n",
    "        ces[i] = old * (_ES(w) - es) / e\n",
    "        w[i] = old\n",
    "    return ces\n",
    "\n",
    "# SSE of the Component ES\n",
    "def SSE_CES(w):\n",
    "    ces = CES(w)\n",
    "    ces = ces - np.mean(ces)\n",
    "    return 1e3 * (ces.T @ ces)\n",
    "\n",
    "# Optimize to find RP based on Expected Shortfall\n",
    "initial_weights = np.ones(n) / n\n",
    "result_es = minimize(SSE_CES, initial_weights, constraints=constraints, bounds=bounds, method='SLSQP')\n",
    "optimized_weights_es = result_es.x\n",
    "\n",
    "ES_RPWeights = pd.DataFrame({'Stock': stocks, 'Weight': optimized_weights_es, 'cEr': stockMeans * optimized_weights_es, 'CES': CES(optimized_weights_es)})\n",
    "\n",
    "print(ES_RPWeights)\n",
    "print(RPWeights)\n",
    "\n",
    "print(\"Degrees of freedom for all stocks:\")\n",
    "for i, stock in enumerate(stocks):\n",
    "    print(stock, \":\", params_list[i][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
